7월 20일 

API 계정 확인
사전 데이터 가져오기 테스트

7월 21일

python에서 그래픽 출력 기능 확인
x축 검색 단어 기준
y축 검색 횟수 기준
(여러 그래프 확인 : 막대 / 선)
검색단어 기간 선택 시 막대로 일 / 월 / 년 표시여부 검증 : 가상의 데이터를 생성해서 테스트

해야 할 부분
1. 데이터를 생성한다 : 문재식(가상데이터 -> json형식으로 실제 뉴스데이터 추출)
1-1. 가상데이터로 먼저 시작
1-2. 날짜별로 정렬, startDate~endDate로 데이터 제시
1-3. 딕셔너리구조 -> 리스트, 튜플 구조변환
1-4. json 파일 입력받는 함수 작성
1-5. 공공데이터(요양기관) -> json 파일 생성


2. 데이터를 변환한다(날짜고려) : 안준표
2-1-1. 여기서 특정 키워드를 입력한다 2-1-2. 빈도수를 세준다 : 반환 자료형 : int형 (수정)
2-2 : 입력값 : (특별시, 광역시, 도이하 시) -> 반환값 (빈도수), 횟수 세는 방법 : "주소"에서 입력단어 있는지 여부를 체크해 빈도수를 반환한다


입력값 : 반환값	출력 : 그래프(x축 : 입력도시, y축 : 빈도수)
3. 변환된 데이터를 그래프로 출력한다. : 조용훈(막대, 선, 파이그래프)
3-1. 반환받은 자료형을 그래프로 출력한다(x축((입력단어),String), y축(횟수,int))

4. 메인코드 작성한다 : 구자원

7월 22일
Facebook 승인 받은 사람은 데이터 가져오기 연습 및 가져온 데이터를 일 / 주 / 월 / 년으로 구분할 수 있도록 정제 
- 연합뉴스/YTN 구독(2010년도 데이터까지 검색 가능해야 함)

해야 할 부분
화면 공유로 4명이서 각자 작성한 코드 보고 리팩토링 시작(중복된 부분이나 양이 많은 코드는 함수로 추출)

리팩토링(double_stick_chart -> 메인으로 작성할때의 문제점, 왜 우리가 리팩토링을 고려하게 되었나), -> 중복된 기능, 
형상관리(어제자, 오늘자 코드) -> 관리하는 방법 : 재식씨가 언급한 깃허브로 commit 조회해서 확인가능

7월 23일
Facebook에서의 데이터가 수집이 어려움으로 1000건의 가상의 데이터를 기준으로 함
검색 단어를 입력하면 현재 시간 기준으로 오늘 하루동안 나온 제목(1주일, 1달, 1년)기준으로 데이터를 정제
제출형식 : 1.소스코드를 메일로, 2. GitHub
저희 수업때 실습코드 기능 : 키워드 -> 키워드 포함된 제목의 기사100개 -> json파일
공공데이터 : 공공데이터(startdate : 21/1/1~ enddate : 21/7/23 획득 완료

정제 하는 단계?
1. json파일을 날짜별로 정렬	- 2. 키워드를 입력(입력키워드 여러개?) 		읽어오는 곳은 : "인용문"
3. 현재일 기준 입력된 키워드 빈도수 산출(일/주/월/년) : 	7/23일 빈도수, 7/17~7/23 빈도수, 6/24~7/23 빈도수, 전체기간 빈도수
4. 그래프 출력 
5. 메인함수 출력?

readme 작성?